{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8AKLAt2xjP_2"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Imputation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Model Pre Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "#Test\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "#Gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Pickle\n",
    "import pickle\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import process_bureau_data\n",
    "from functions import perform_PCA\n",
    "from functions import scale_data\n",
    "from functions import get_top_30_corr\n",
    "from functions import model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Assets/application_train.csv')\n",
    "bureau = pd.read_csv('Assets/bureau.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing bureau data from \n",
    "bureau_data = process_bureau_data(bureau)\n",
    "\n",
    "#Scale Data to perform PCA\n",
    "scaled_data = scale_data(bureau_data)\n",
    "\n",
    "#Perform PCA On Bureau Data\n",
    "pca_b = perform_PCA(scaled_data , 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bureau / Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_all = pd.concat([bureau_data['SK_ID_CURR'] , pca_b], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VNfOQsjY8wL9"
   },
   "outputs": [],
   "source": [
    "#Merge\n",
    "\n",
    "df['TARGET_X_AMT_CREDIT'] = df.AMT_CREDIT * df.TARGET\n",
    "dummy_df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 correlated features for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30 = get_top_30_corr(dummy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing Data & Merge All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "cols_with_missing  = df_30.isnull().sum()[df_30.isnull().sum() > 0].index\n",
    "    \n",
    "for col in cols_with_missing:\n",
    "    df_30[col].fillna(df_30[col].mean(), inplace = True)\n",
    "\n",
    "#Merge application data & Bureau\n",
    "df_30 = pd.concat([df[['SK_ID_CURR']], df_30], axis = 1)\n",
    "data_for_model = pd.merge(df_30 , bureau_all , on = 'SK_ID_CURR', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in cols_with_missing[:1]:\n",
    "    \n",
    "#     lr = LinearRegression()\n",
    "    \n",
    "#     testdf = df_30[df_30[col].isnull()==True]\n",
    "#     traindf = df_30[df_30[col].isnull()==False]\n",
    "    \n",
    "#     y = traindf[col]\n",
    "#     traindf.drop(col,axis=1,inplace=True)\n",
    "    \n",
    "#     lr.fit(traindf,y)\n",
    "#     testdf.drop(col,axis=1,inplace=True)\n",
    "    \n",
    "#     pred = lr.predict(testdf)\n",
    "#     testdf[col]= pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models with Credit scores\n",
    "X = data_for_model.drop(columns=[ 'TARGET_X_AMT_CREDIT'])\n",
    "y = data_for_model['TARGET_X_AMT_CREDIT']\n",
    "\n",
    "X.dropna(inplace = True)\n",
    "X = X.drop(columns = ['SK_ID_CURR'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "#Models w/o Credit\n",
    "\n",
    "X_no_credit = data_for_model.drop(columns=[ 'TARGET_X_AMT_CREDIT' , 'EXT_SOURCE_3', 'EXT_SOURCE_2' , 'EXT_SOURCE_1'])\n",
    "y_no_credit = data_for_model['TARGET_X_AMT_CREDIT']\n",
    "\n",
    "X_train_nc, X_test_nc, y_train_nc, y_test_nc = train_test_split(X_no_credit, y_no_credit, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests Regressor / GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-30137447468.998 total time= 1.1min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-30405236852.371 total time= 1.1min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-30119862655.158 total time= 1.1min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-30426453693.966 total time= 1.1min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-30151996913.809 total time= 1.1min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-30392395554.624 total time= 1.2min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-31155517270.555 total time= 2.3min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-31367068160.123 total time= 2.3min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-31026141427.311 total time= 2.3min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-31281800088.523 total time= 2.2min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-30968957933.911 total time= 2.1min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-31206292132.384 total time= 2.1min\n"
     ]
    }
   ],
   "source": [
    "# Model with Target Varibale - Target x Amt Credit\n",
    "normal = model_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-30106036750.293 total time= 1.1min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-30398692721.742 total time= 1.1min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-30144394370.500 total time= 1.1min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-30422352709.233 total time= 1.1min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-30137422094.653 total time= 1.1min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-30434648693.278 total time= 1.1min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-31135918501.046 total time= 2.1min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-31410096577.948 total time= 2.1min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-30988315511.400 total time= 2.2min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-31271982125.779 total time= 2.1min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-30901955266.274 total time= 2.1min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-31181291473.047 total time= 2.1min\n"
     ]
    }
   ],
   "source": [
    "# Model with Target Varibale - Target x Amt Credit * .1\n",
    "ten_percent = model_data(X_train, X_test * .1, y_train, y_test * .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-30113961170.631 total time= 1.2min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-30411535699.534 total time= 1.2min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-30173214230.602 total time= 1.2min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-30400142234.735 total time= 1.2min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-30122388668.340 total time= 1.2min\n",
      "[CV 2/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-30390310566.180 total time= 1.2min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-31146499927.996 total time= 2.3min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-31393449947.169 total time= 2.2min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-31036210300.783 total time= 2.3min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-31324039588.076 total time= 2.1min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-30941196944.589 total time= 2.4min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-31199440791.618 total time= 2.3min\n"
     ]
    }
   ],
   "source": [
    "# Model with Target Varibale - Target x Amt Credit Loss of 3% Fixed interest rate over compounded 30 years\n",
    "fixed_interest = .03\n",
    "years = 30\n",
    "\n",
    "\n",
    "new_X_test = [principal * (1 + fixed_interest/ 12) ** (12*years) for principal in y_train]\n",
    "new_y_test = [principal * (1 + fixed_interest / 12) ** (12*years) for principal in y_test]\n",
    "\n",
    "\n",
    "compounded_model = model_data(X_train, new_X_test, y_train, new_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model w/o Credit Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-30914677647.427 total time=  58.4s\n",
      "[CV 2/2] END max_depth=10, min_samples_split=5, n_estimators=100;, score=-31379108777.310 total time= 1.0min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-30880810859.066 total time=  59.2s\n",
      "[CV 2/2] END max_depth=10, min_samples_split=10, n_estimators=100;, score=-31394906204.456 total time= 1.0min\n",
      "[CV 1/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-30909752252.925 total time=  59.1s\n",
      "[CV 2/2] END max_depth=10, min_samples_split=15, n_estimators=100;, score=-31392926925.107 total time=  57.6s\n",
      "[CV 1/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-31924205015.101 total time= 1.8min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=5, n_estimators=100;, score=-32417764733.126 total time= 1.9min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-31875034814.830 total time= 1.8min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=10, n_estimators=100;, score=-32333269859.511 total time= 1.8min\n",
      "[CV 1/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-31720758477.177 total time= 1.8min\n",
      "[CV 2/2] END max_depth=None, min_samples_split=15, n_estimators=100;, score=-32212293343.088 total time= 1.9min\n"
     ]
    }
   ],
   "source": [
    "# Model w/o credit scores with Target Varibale - Target x Amt Credit\n",
    "normal_no_creidt = model_data(X_train_nc, X_test_nc, y_train_nc, y_test_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(normal, open('Assets/original_model.pkl', 'wb'))\n",
    "pickle.dump(ten_percent, open('Assets/ten_percent_model.pkl', 'wb'))\n",
    "pickle.dump(compounded_model, open('Assets/compounded_model.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(normal_no_creidt , open('Assets/normal_no_creidt.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('Assets/X.csv')\n",
    "y.to_csv('Assets/y.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of mads.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
